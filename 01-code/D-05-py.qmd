---
title: 'Practice Code: Day 5'
author:
  name: 'Constantin Manuel Bosancianu'
  orcid: 0000-0001-7950-9798
  email: bosancianu@icloud.com
date: 'August 2, 2019'
bibliography: ../references.bib
execute:
  eval: true
  echo: true
  warning: false
  error: false
format:
  html:
    toc: true
    code-fold: true
    toc-location: left
    theme: minty
    number-sections: true
    reference-location: margin
    embed-resources: true
jupyter: python3
---

# Introduction

We start as yesterday, by loading a few needed packages, and by defining a few custom functions we use below.

```{python load-packages}
import pandas as pd
pd.set_option('display.precision', 6)
import numpy as np
import pyreadr as prr
import os
import random
from plotnine import *
import statsmodels.formula.api as sm1
import statsmodels.api as sm2
import statsmodels.stats.api as sms
import scipy as sp
import matplotlib.pyplot as plt
from IPython.display import HTML
```

We also define here the standard centering function we've been using so far.

```{python helpful-functions}
def fun_two_SD(x):
    return (x - np.mean(x, axis = 0)) / (2 * np.std(x))
```

# Data input and preparation

We will start with a new data set today, though the focus will continue to be on predicting political efficacy. The data comes from waves 1-4 of the CSES, and it has an associated codebook which you can find in the `06-docs` subfolder.

The most important variables are:

1. `poleff`: index of political efficacy, constructed as an average of 2 items measuring political efficacy (`D3009` and `D3010`). Higher values denote a greater sense of political efficacy
2. `male`: gender (man = 1; woman = 0)
3. `age`: age, measured in years
4. `educat`: highest educational level, measured on a 10-point scale (from "no formal education" to "doctorate or equivalent")
5. `income`: country-specific income quintile in which the respondent is situated. 0 = bottom 20%; ... ; 4 = top 20%
6. `turnout`: R. turned out to vote in election (1=yes; 0=no)
7. `unmemb`: R. is union member (1=yes; 0=no)
8. `gini10`: net Gini value at national-level, measured in 10-point units
9. `corr_ind`: political corruption index from V-DEM data (0-1 interval, with higher values denoting more corruption)
10. `comp`: country has compulsory voting laws (1=yes; 0=no)
11. `cnt.year`: unique indicator for country-year

We keep only the variables we're interested in - these are some of the same variables we've been using in past days, though naturally the coding will differ.

I will also only keep countries that have at least 2 surveys in the data (the reason is that I want to estimate the within-country effect of country-year variables). I also exclude a mail-back survey for Germany, and keep only the telephone one for that same year.

```{python read-data}
result = prr.read_r("../02-data/02-CSES14-subset.rds")
df_cses = result[None]

df_cses = df_cses[['country', 'year', 'cnt.year', 'poleff', 'male',
                   'age', 'educat', 'income', 'unmemb', 'gini10',
                   'corr_ind', 'comp', 'mdmh']].\
               dropna().\
               rename({'cnt.year': 'cnt_year'}, axis = 1)

df_cses = df_cses[df_cses.country.isin(["Australia", "Austria", "Brazil", "Bulgaria",
                          "Canada", "Czech Republic", "Denmark", "Finland",
                          "France", "Germany", "Greece", "Hungary", "Iceland",
                          "Israel", "Mexico", "Netherlands", "New Zealand",
                          "Norway", "Philippines", "Poland", "Portugal",
                          "Romania", "Slovakia", "Slovenia", "South Korea",
                          "Spain", "Sweden", "Switzerland", "Taiwan",
                          "Thailand", "Turkey", "United Kingdom"])]
df_cses = df_cses[df_cses.cnt_year != "DEU22002"]
df_cses.loc[df_cses['cnt_year'] == "DEU12002", 'cnt_year'] = "DEU_2002"

df_dumm = pd.get_dummies(df_cses['income'], prefix = 'inc')
df_dumm = df_dumm.rename({'inc_0.0': 'inc1',
                          'inc_1.0': 'inc2',
                          'inc_2.0': 'inc3',
                          'inc_3.0': 'inc4',
                          'inc_4.0': 'inc5'}, axis = 1)
df_cses = pd.concat([df_cses, df_dumm], axis = 1)
```

We are left with 149,612 respondents, from 123 surveys (country years), from 46 countries.^[You can easily get this information by applying the `nunique()` function to the respective columns.]

# Centering

Let's go again through the centering procedures we went through yesterday, and generate the last 3 models we looked at.

```{python group-mean-centering-1}
df_grouped = df_cses.groupby('cnt_year')[['age', 'male', 'educat',
                                          'inc1', 'inc2', 'inc3',
                                          'inc4', 'inc5', 'unmemb']].\
                transform(lambda x: fun_two_SD(x))
df_grouped = df_grouped.rename({'age': 'ageCWC',
                                'male': 'maleCWC',
                                'educat': 'educCWC',
                                'inc1': 'inc1CWC',
                                'inc2': 'inc2CWC',
                                'inc3': 'inc3CWC',
                                'inc4': 'inc4CWC',
                                'inc5': 'inc5CWC',
                                'unmemb': 'membCWC'},
                               axis = 1)

df_cses = pd.concat([df_cses, df_grouped], axis = 1)
```

At level 2, the group-mean centering requires an additional step.^[This is because our data set came as a single file, with both individual-level and group-level indicators included. Observe the way in which 4 countries (Denmark, Spain, Sweden, and Switzerland) drop out of the sample, since there is no longitudinal variance in the yearly observations for perceptions of corruption.]

```{python group-mean-centering-2}
df_grouped = df_cses.groupby(['country', 'year'])[['gini10', 'corr_ind']].\
    mean().\
    reset_index(level = [0, 1])
# A small data input problem is leading to Spain staying in the sample
df_grouped.loc[(df_grouped['country'] == "Spain") &\
      (df_grouped['year'] == 2000), 'corr_ind'] = 0.04

df_agg = df_grouped.groupby('country')[['gini10', 'corr_ind']].\
    transform(lambda x: fun_two_SD(x)).\
    rename({'gini10': 'giniCWC',
            'corr_ind': 'corrCWC'}, axis = 1)
df_agg = pd.concat([df_agg, df_grouped[['country', 'year']]], axis = 1)

df_cses = df_cses.merge(df_agg, on = ['country', 'year'], how = 'left')
```

At the country level, I center MDMH, as well as the indicator for compulsory voting. Although MDMH is technically a country-year variable, I will first aggregate it at the country-level, since it tends to be fairly stable over time (electoral changes happen relatively rarely).

```{python grand-mean-centering}
df_grouped = df_cses.groupby(['country', 'year'])[['mdmh', 'comp']].\
    mean().\
    groupby('country')[['mdmh', 'comp']].\
    mean().\
    reset_index(level = 0)

df_grouped[['mdmhCGM', 'compCGM']] = df_grouped[['mdmh', 'comp']].\
      apply(fun_two_SD)
df_grouped = df_grouped.drop(columns = ['mdmh', 'comp'])

df_cses = df_cses.merge(df_grouped, on = 'country', how = 'left')
```

One last thing to check: is compulsory voting truly a L3 variable?

```{python check-merging, results='asis'}
df_grouped = df_cses.groupby(['country', 'year']).\
    agg(comp = ('comp', 'mean')).\
    groupby('country').\
    agg(comp = ('comp', 'mean')).\
    reset_index(level = 0)

HTML(df_grouped.\
     rename({'country': 'Country',
             'comp': 'Compulsory voting laws'}, axis = 1).\
     to_html())
```

# 3-level models

Now, for the modeling - let's start as usual: with a null model. **Python** is a bit more forgiving than **R** in terms of group labels here. Even if L2 IDs are similar between L3 groups, **Python** will still consider them as independent groups.^[See the information at: [https://www.statsmodels.org/dev/examples/notebooks/generated/variance_components.html](https://www.statsmodels.org/dev/examples/notebooks/generated/variance_components.html).]

```{python mlm-null-specification}
vc = {'cnt_year': '0 + C(cnt_year)'}
mlm_0 = sm1.mixedlm("poleff ~ 1",
                    re_formula = "1",
                    data = df_cses,
                    vc_formula = vc,
                    groups = 'country').fit()
```

You have all the information needed to compute the 2 ICCs now:

1. ICC3 = $0.2018/(0.2018 + 0.1296 + 4.2907)$
2. ICC23 = $(0.2018 + 0.1296)/(0.2018 + 0.1296 + 4.2907)$

Both numbers suggest that in this sample there is very little between country, or between country-year variance in political efficacy to be explained.

```{python mlm-specification-1}
df_cses = df_cses.dropna()
vc = {'cnt_year': '0 + C(cnt_year)'}
mlm_1 = sm1.mixedlm("poleff ~ 1 + ageCWC + maleCWC + educCWC + inc2CWC + inc3CWC +\
                        inc4CWC + inc5CWC + membCWC + giniCWC + corrCWC + compCGM +\
                        mdmhCGM",
                    re_formula = "1",
                    data = df_cses,
                    vc_formula = vc,
                    groups = 'country').fit()
```

Random slopes can be added in the same way, though a bit of care neeeds to be taken when assessing at which level to allow them to vary.

```{python mlm-specification-2}
vc = {'cnt_year': '0 + C(cnt_year)', 'educCWC': '0 + educCWC'}
mlm_2 = sm1.mixedlm("poleff ~ 1 + ageCWC + maleCWC + educCWC + inc2CWC +\
                        inc3CWC + inc4CWC + inc5CWC + membCWC + giniCWC +\
                        corrCWC + educCWC * corrCWC + compCGM + mdmhCGM",
                    re_formula = "1",
                    data = df_cses,
                    vc_formula = vc,
                    groups = 'country').fit()
```

```{python display-results}
print(mlm_1.summary(), mlm_2.summary())
```

# Practice session

Try your hand, by yourselves, at running a few models from the ground up. I have added in the `02-data` subfolder a dataset that deals with contributions by the tobacco lobby to members of the US Congress. The data is called `03-contributions.sav`; each line contains information about a specific member of the House or Senate. The data is sourced from @luke_multilevel_2004.

The following variables are found in the data:

1. `house`: whether the legislator is a member of the House (1 = House; 0 = Senate)
2. `state`: state code
3. `sid`: numeric ID for the state
4. `lastname`: last name of the legislator
5. `votepct`: % of time that a legislator votes in line with the interest of tobacco companies (0 - 1 scale)
6. `party`: legislator is a member of the GOP (0 = Democrat; 1 = GOP)
7. `money`: total tobacco-linked lobby groups contributions to the legislator between 1993 and 2000 (in raw USD amounts)
8. `acres`: Number (in 1000s) of acres of tobacco harvested in the state in 1999
9. `pct100`: % of time that a legislator votes in line with the interest of tobacco companies (0 - 100 scale)
10. `money1000`: total tobacco-linked lobby groups contributions to the legislator between 1993 and 2000 (in 1000s of USD)

Level-1 variables are `house`, `pct100`, `money1000`, `party`, and `lastname`. Level-2 variables are `acres`. ID variables are `state` and `sid` (either one).

Try to explain `pct100`: what % of the time a legislator votes in favor of tobacco companies.

Go through all the steps of choosing a Level-1 and a Level-2 model (it will be pretty simple, since there are very few variables you can work with).

Tasks:

1. Run a null model, to assess whether you need to engage in MLM, and produce an ICC
2. Center predictors (at both Level-1 and Level-2)
3. Run a random intercept model with individual-level predictors of `pct100`
4. Run a random intercept model with some state-level predictors as well, in addition to the individual-level ones
5. Run a random slope model, with a varying slope for `party`, but with no predictors for this slope
6. Run a random slope model, which includes `acres` as a predictor for the slope of `party`
7. Display the effect of the cross-level interaction at the previous point in a graphical format
8. Produce a table of comparisons for the estimates of these 5 models you've run.^[The table can be a screenshot from the R console window, a HTML table, or a LaTeX table.]
9. Which is the best fitting model of the series? Please perform a statistical test to assess this

# Package versions

Package versions used in this script.

1. `ipykernel`         6.21.2
2. `ipython`           8.11.0
3. `jupyter_client`    8.0.3
4. `jupyter_core`      5.2.0
5. `matplotlib`        3.7.0
6. `matplotlib-inline` 0.1.6
7. `numpy`             1.24.2
8. `pandas`            1.5.3
9. `plotnine`          0.10.1
10. `pyreadr`          0.4.7
11. `scipy`            1.10.1
12. `stargazer`        0.0.5
13. `statsmodels`      0.13.5